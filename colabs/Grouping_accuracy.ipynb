{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eW0TkpaQf2VW"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q dlcdn.apache.org/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import DataFrame as SparkDataFrame\n",
        "from pyspark.sql.types import IntegerType, FloatType, StringType, StructType\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, jaccard_score, confusion_matrix\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzbzwFI_gkAm",
        "outputId": "ed71a629-af56-428b-f5db-43cb7f1a7cc7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(columns_used_for_grouping: list, Year: int, Month: int):\n",
        "  spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()\n",
        "  columns = ['lon', 'lat', 'Date'] + columns_used_for_grouping\n",
        "  schema = StructType()\n",
        "  for i in columns:\n",
        "    if i == \"Date\":\n",
        "      schema = schema.add(i, IntegerType(), True)\n",
        "    else:\n",
        "      schema = schema.add(i, FloatType(), True)\n",
        "  nasa = spark.read.format('csv').option(\"header\", True).schema(schema).load('/content/drive/MyDrive/BigMess/NASA/NASA.csv')\n",
        "  nasa.createOrReplaceTempView(\"nasa\")\n",
        "  nasa_ym = spark.sql(\"\"\"\n",
        "        SELECT\n",
        "        CAST(SUBSTRING(CAST(Date AS STRING), 1, 4) AS INT) AS Year,\n",
        "        CAST(SUBSTRING(CAST(Date AS STRING), 5, 2) AS INT) AS Month,\n",
        "        n.*\n",
        "        FROM nasa n\n",
        "        \"\"\")\n",
        "  nasa_ym = nasa_ym.drop(\"Date\")\n",
        "  nasa_ym.createOrReplaceTempView(\"nasa_ym\")\n",
        "  query = f\"\"\"\n",
        "  SELECT\n",
        "  *\n",
        "  FROM nasa_ym\n",
        "  WHERE Year = {Year} AND Month = {Month}\n",
        "  ORDER BY lon, lat, Year, Month\n",
        "  \"\"\"\n",
        "  SparkDataFrame_Year_Month = spark.sql(query)\n",
        "  df_Year_month = SparkDataFrame_Year_Month.toPandas()\n",
        "  NASA_an = pd.read_csv('/content/drive/MyDrive/BigMess/NASA/NASA_an.csv', sep=';')\n",
        "  NASA_an['pustynia_i_step'] = NASA_an.pustynia + NASA_an.step\n",
        "  NASA_Year_Month = df_Year_month[[\"lon\", \"lat\"] + columns_used_for_grouping].merge(NASA_an, left_on=['lon','lat'], right_on = ['lon','lat'], how='inner')\n",
        "  X_test = NASA_Year_Month[columns_used_for_grouping]\n",
        "  y_test = NASA_Year_Month[[\"pustynia_i_step\"]]\n",
        "  return X_test, y_test"
      ],
      "metadata": {
        "id": "3bYl5Plzo_0H"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationModelEvaluator:\n",
        "    def __init__(self, X_test, y_test):\n",
        "        self.X_test = X_test\n",
        "        self.y_test = y_test\n",
        "    def evaluate_model(self, model):\n",
        "        y_pred = model.fit_predict(self.X_test)\n",
        "        accuracy = accuracy_score(self.y_test, y_pred)\n",
        "        precision = precision_score(self.y_test, y_pred)\n",
        "        recall = recall_score(self.y_test, y_pred)\n",
        "        f1 = f1_score(self.y_test, y_pred)\n",
        "        jaccard = jaccard_score(self.y_test, y_pred)\n",
        "        confusion_mat = confusion_matrix(self.y_test, y_pred)\n",
        "        metrics_dict = {\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision': precision,\n",
        "            'Recall': recall,\n",
        "            'F1 Score': f1,\n",
        "            'Jaccard Score': jaccard,\n",
        "            'Confusion Matrix': confusion_mat\n",
        "        }\n",
        "        return metrics_dict"
      ],
      "metadata": {
        "id": "oIrGsrBLgloo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dzia≈Çanie:\n",
        "# X_test, y_test = preprocessing(['Rainf', 'Evap', 'AvgSurfT','Albedo', 'SoilT_10_40cm', 'GVEG', 'PotEvap', 'RootMoist', 'SoilM_100_200cm'], 2023, 7)\n",
        "# evaluator = ClassificationModelEvaluator(X_test, y_test)\n",
        "# metrics = evaluator.evaluate_model(KMeans(n_clusters = 2, init='k-means++', random_state = 123))\n",
        "# print(metrics)"
      ],
      "metadata": {
        "id": "ENtUGbKzgpMq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d404ae3-140d-4033-b9f3-9a356b616706"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Accuracy': 0.722, 'Precision': 0.5304659498207885, 'Recall': 0.9487179487179487, 'F1 Score': 0.6804597701149426, 'Jaccard Score': 0.5156794425087108, 'Confusion Matrix': array([[213, 131],\n",
            "       [  8, 148]])}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}