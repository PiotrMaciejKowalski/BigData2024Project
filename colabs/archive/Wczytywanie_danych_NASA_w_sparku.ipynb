{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiotrMaciejKowalski/BigData2024Project/blob/Szablon-wczytywania-danych-w-sparku/colabs/Wczytywanie_danych_NASA_w_sparku.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM663YMlg_E-"
      },
      "source": [
        "# Wczytywanie danych w sparku"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gBFVF2WoyXj"
      },
      "source": [
        "Utworzenie środowiska pyspark do obliczeń:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q dlcdn.apache.org/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import IntegerType, FloatType, StringType, StructType"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yEZdu1Ko4II"
      },
      "source": [
        "Utowrzenie sesji:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pG05GbFHhmNI"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ5qVugtpApM"
      },
      "source": [
        "Połączenie z dyskiem:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cDV6XvNgTdV",
        "outputId": "651ca38a-c407-4285-9a73-8a7e777f2977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDZ6ImTlpHOv"
      },
      "source": [
        "Wczytanie danych NASA znajdujących się na dysku w sparku:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_Goo147Lzr6B"
      },
      "outputs": [],
      "source": [
        "columns = ['lon', 'lat', 'Date', 'SWdown', 'LWdown', 'SWnet', 'LWnet', 'Qle', 'Qh', 'Qg', 'Qf', 'Snowf', 'Rainf', 'Evap', 'Qs', 'Qsb', 'Qsm', 'AvgSurfT', 'Albedo', 'SWE', 'SnowDepth', 'SnowFrac', 'SoilT_0_10cm', 'SoilT_10_40cm', \n",
        "           'SoilT_40_100cm', 'SoilT_100_200cm', 'SoilM_0_10cm', 'SoilM_10_40cm', 'SoilM_40_100cm', 'SoilM_100_200cm', 'SoilM_0_100cm', 'SoilM_0_200cm', 'RootMoist', 'SMLiq_0_10cm', 'SMLiq_10_40cm', 'SMLiq_40_100cm', 'SMLiq_100_200cm', \n",
        "           'SMAvail_0_100cm', 'SMAvail_0_200cm', 'PotEvap', 'ECanop', 'TVeg', 'ESoil', 'SubSnow', 'CanopInt', 'ACond', 'CCond', 'RCS', 'RCT', 'RCQ', 'RCSOL', 'RSmin','RSMacr', 'LAI', 'GVEG', 'Streamflow']\n",
        "\n",
        "# Utworzenie schematu określającego typ zmiennych\n",
        "schema = StructType()\n",
        "for i in columns:\n",
        "  if i == \"Date\":\n",
        "    schema = schema.add(i, StringType(), True)\n",
        "  else:\n",
        "    schema = schema.add(i, FloatType(), True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Anm2lmTahQJx",
        "outputId": "47d006ee-2e4e-41c0-cc27-b737afe5a55d"
      },
      "outputs": [],
      "source": [
        "# Wczytanie zbioru Nasa w sparku\n",
        "nasa = spark.read.format('csv').option(\"header\", True).schema(schema).load('/content/drive/MyDrive/BigMess/NASA/NASA.csv')\n",
        "nasa.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3qU94A9p5BT"
      },
      "source": [
        "Zanim zaczniemy pisać kwerendy należy jeszcze dodać nasz DataFrame (df) do \"przestrzeni nazw tabel\" Sparka:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "bSPBX5fPi7Ub"
      },
      "outputs": [],
      "source": [
        "nasa.createOrReplaceTempView(\"nasa\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLvsomiX7RxP"
      },
      "source": [
        "Rodzielenie kolumny \"Date\" na kolumny \"Year\" oraz \"Month\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "PUp1C5Qq3k-5"
      },
      "outputs": [],
      "source": [
        "nasa_ym = spark.sql(\"\"\"\n",
        "          SELECT\n",
        "          CAST(SUBSTRING(CAST(Date AS STRING), 1, 4) AS INT) AS Year,\n",
        "          CAST(SUBSTRING(CAST(Date AS STRING), 5, 2) AS INT) AS Month,\n",
        "          n.*\n",
        "          FROM nasa n\n",
        "          \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nasa_ym = nasa_ym.drop(\"Date\")\n",
        "nasa_ym.createOrReplaceTempView(\"nasa_ym\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
