# -*- coding: utf-8 -*-
"""agregacje_kilkuletnie.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EctTE3Yquf3QTyiy5_Tu780RHGTQY047

# Instalacja oraz import niezbędnych bibliotek
"""

!pip install datashader
!pip install holoviews hvplot colorcet
!pip install geoviews
!pip install pyspark

from typing import Optional, Tuple, List

import copy
import warnings
warnings.filterwarnings('ignore')

import numpy as np
import matplotlib.pyplot as plt
import random
import seaborn as sns
import matplotlib as mpl
import pandas as pd
import pickle

import sklearn
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

from imblearn.over_sampling import RandomOverSampler, SMOTE

import datashader as ds
import datashader.transfer_functions as tf
import holoviews as hv
import geoviews as gv
import geoviews.tile_sources as gts
from holoviews.operation.datashader import datashade
from holoviews import opts

from IPython.display import IFrame
from IPython.core.display import display

from bokeh.plotting import show, output_notebook
from bokeh.layouts import row

import pyspark
from pyspark.sql import SparkSession, DataFrame as SparkDataFrame, functions as F, Window
from pyspark.sql.types import IntegerType, FloatType, StringType, StructType

import lightgbm as lgb

from google.colab import drive
drive.mount("/content/drive")

"""## Funkcje

Funkcje z notatnika Rafała:
"""

class BalanceDataSet():
  '''
  Two techniques for handling imbalanced data.
  '''
  def __init__(
      self,
      X: pd.DataFrame,
      y: pd.DataFrame,
      random_seed: int = 2023
      ) -> None:
      self.X = X
      self.y = y
      assert len(self.X)==len(self.y)
      self.random_seed = random_seed
      self.oversample = RandomOverSampler(sampling_strategy='auto', random_state=random_seed)
      self.smote = SMOTE(random_state=random_seed)

  def useOverSampling(
      self,
      ) -> Tuple[pd.DataFrame, pd.DataFrame]:
    return self.oversample.fit_resample(self.X, self.y)

  def useSMOTE(
      self,
      ) -> Tuple[pd.DataFrame, pd.DataFrame]:
    return self.smote.fit_resample(self.X, self.y)

def summary_model(model: sklearn.base.BaseEstimator, X: pd.DataFrame, y: pd.DataFrame, labels_names: List) -> None:
  y_pred = model.predict(X)
  y_real= y
  cf_matrix = confusion_matrix(y_real, y_pred)
  group_counts = ["{0:0.0f}".format(value) for value in cf_matrix.flatten()]
  group_percentages = ["{0:.2%}".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]
  labels = [f"{v1}\n{v2}" for v1, v2 in zip(group_counts,group_percentages)]
  labels = np.asarray(labels).reshape(len(labels_names),len(labels_names))
  sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Reds',xticklabels=labels_names,yticklabels=labels_names)
  plt.xlabel('Predykcja')
  plt.ylabel('Rzeczywistość')
  plt.show()

"""Funkcja zwracająca cztery metryki oceniające klasyfikator:"""

def show_metrics(model: sklearn.base.BaseEstimator, X: pd.DataFrame, y: pd.DataFrame) -> None:
  y_pred = model.predict(X)
#  print("Macierz błędu\n", confusion_matrix(y_true, y_pred), "\n")
  accuracy = accuracy_score(y, y_pred)
  print(f"Dokładność (accuracy): {accuracy*100:.2f}%")
  precision = precision_score(y, y_pred)
  print(f"Precyzja (precision): {precision*100:.2f}%")
  recall = recall_score(y, y_pred)
  print(f"Czułość (recall): {recall*100:.2f}%")
  f1 = f1_score(y, y_pred)
  print(f"F1-score: {f1*100:.2f}%")

"""## Sklonowanie repozytorium i import zawartych w nim funkcji"""

!git clone https://github.com/PiotrMaciejKowalski/BigData2024Project.git

!chmod 755 /content/BigData2024Project/src/setup.sh
!/content/BigData2024Project/src/setup.sh

import sys
sys.path.append('/content/BigData2024Project/src')

from start_spark import initialize_spark

from big_mess.loaders import default_loader
from agg_classification_eval import overYearMonthStats, plot_comparison, plot_map, show_metrics, prepare_agg_data_for_training

"""# Załadowanie zbioru danych"""

initialize_spark()

spark = SparkSession.builder\
        .master("local")\
        .appName("Colab")\
        .config('spark.ui.port', '4050')\
        .getOrCreate()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# nasa = default_loader(spark)
# nasa.show(5)

nasa.createOrReplaceTempView("nasa")

"""# Średnie wieloletnie dla poszczególnych miesięcy

Zastosujmy teraz funkcję `overYearMonthStats` na naszym datasecie, dla każdej z rozważanych kolumn pomiarowych, przyjmując $n\in\{3, 4, 5\}$ (tj. średnie 3, 4 i 5-letnie). Następnie wyodrębnijmy do oddzielnych dataframe'ów lata $2000$, $2020$, $2022$ oraz $2023$.
"""

columns_to_avg = ["Rainf", "Evap", "AvgSurfT", "Albedo", "SoilT_40_100cm", "GVEG", "PotEvap", "RootMoist", "SoilM_100_200cm"]

for n in [3, 4, 5]:
    result_df = overYearMonthStats(nasa, columns_to_avg, n=n)
    for year in [2023, 2022, 2020, 2000]:
        filtered_data = result_df.filter(f'Year = {year}')
        pd_monthly_avg = filtered_data.toPandas()
        pd_monthly_avg.to_csv(f'/content/drive/MyDrive/BigMess/NASA/monthly_avg/{n}years/NASA_monthly_avg_{year}.csv')

"""# Dane do modeli

Z wyodrębnionych zbiorów danych weźmiemy pomiary z lipca 2023, ponieważ na takich trenowane były pierwotne modele. Po zmerge'owaniu ze zbiorem anotowanym, pozostawiamy tylko kolumny ze współrzędnymi, ze średnimi oraz kolumnę 'pustynia' ograniczając się jedynie do stwierdzenia czy dana lokalizacja jest pustynią czy nie.

Zaimportujmy zbiór anotowany:
"""

NASA_sample_an = pd.read_csv('/content/drive/MyDrive/BigMess/NASA/NASA_an.csv', sep=';')

"""Wyodrębnijmy pożądane dane z uśrednionych zbiorów przy użyciu funkcji `prepare_agg_data_for_training`:"""

monthly_avg_3_july2023, monthly_avg_3_july2023_an_merge = prepare_agg_data_for_training(nasa_sample_an=NASA_sample_an, year=2023, month=7, n_years=3)
monthly_avg_4_july2023, monthly_avg_4_july2023_an_merge = prepare_agg_data_for_training(nasa_sample_an=NASA_sample_an, year=2023, month=7, n_years=4)
monthly_avg_5_july2023, monthly_avg_5_july2023_an_merge = prepare_agg_data_for_training(nasa_sample_an=NASA_sample_an, year=2023, month=7, n_years=5)

"""## Porównanie na wykresach

Porównamy na wykresach słupkowych wartości rozważanych przez nas zmiennych, w każdym z uśrednionych zbiorów, dla 10 losowo wybranych lokalizacji:
"""

var_list = ['Rainf', 'Evap', 'AvgSurfT', 'Albedo', 'SoilT_40_100cm', 'GVEG', 'PotEvap', 'RootMoist', 'SoilM_100_200cm']
dfs_to_compare = [monthly_avg_3_july2023_an_merge, monthly_avg_4_july2023_an_merge, monthly_avg_5_july2023_an_merge]

for var in var_list:
  plot_comparison(dfs_to_compare, var)
  print()

"""Najbardziej zauważalne różnice między zbiorami można dostrzec w przypadku zmiennej Rainf, reszta wydaje się przyjmować nieco bardziej stabilne wartości średnich kilkuletnich.

# Las losowy

## Trening i test modelu przy użyciu nowych danych i zbioru anotowanego
"""

best_rf = RandomForestClassifier(max_depth=8, min_samples_leaf=4, n_estimators=70, random_state=3)

"""### Średnie 3-letnie"""

X = monthly_avg_3_july2023_an_merge.drop(columns=['lon', 'lat', 'pustynia'])
y = monthly_avg_3_july2023_an_merge['pustynia']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2023)

rf_monthly_avg_3_july2023 = best_rf.copy()
rf_monthly_avg_3_july2023.fit(X_train, y_train)

"""Zastosujmy model na pełnych danych:"""

monthly_avg_3_july2023_pred = monthly_avg_3_july2023.copy()
monthly_avg_3_july2023_pred['pustynia'] = rf_monthly_avg_3_july2023.predict(
    monthly_avg_3_july2023.loc[:, [col for col in monthly_avg_3_july2023.columns if col.startswith('monthly_avg')]])

output_notebook()
show(plot_map(df=monthly_avg_3_july2023_pred, parameter_name='pustynia',
              colormap=dict(zip(['1', '0'], ['yellow', 'green'])),
              title='Pustynie (1) i niepustynie (0) - las losowy (lipiec 2023, średnia 3-letnia)',
              point_size=3, alpha=0.7))

"""##### Ocena na zbiorze treningowym"""

summary_model(rf_monthly_avg_3_july2023, X_train, y_train, ['0','1'])

show_metrics(rf_monthly_avg_3_july2023, X_train, y_train)

"""##### Ocena na zbiorze testowym"""

summary_model(rf_monthly_avg_3_july2023, X_test, y_test, ['0', '1'])

show_metrics(rf_monthly_avg_3_july2023, X_test, y_test)

"""##### Próba treningu na zbalansowanym datasecie"""

X_train_bal, y_train_bal = BalanceDataSet(X_train, y_train).useSMOTE()

rf_monthly_avg_3_july2023_bal = best_rf.copy()
rf_monthly_avg_3_july2023_bal.fit(X_train_bal, y_train_bal)

show_metrics(rf_monthly_avg_3_july2023_bal, X_train_bal, y_train_bal)

show_metrics(rf_monthly_avg_3_july2023_bal, X_test, y_test)

"""W tym wypadku model gorzej radzi sobie na zbiorze testowym.

### Średnie 4-letnie
"""

X = monthly_avg_4_july2023_an_merge.drop(columns=['lon', 'lat', 'pustynia'])
y = monthly_avg_4_july2023_an_merge['pustynia']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2023)

rf_monthly_avg_4_july2023 = best_rf.copy()
rf_monthly_avg_4_july2023.fit(X_train, y_train)

"""Zastosujmy model na pełnych danych:"""

monthly_avg_4_july2023_pred = monthly_avg_4_july2023.copy()
monthly_avg_4_july2023_pred['pustynia'] = rf_monthly_avg_4_july2023.predict(monthly_avg_4_july2023.loc[:, [col for col in monthly_avg_4_july2023.columns if col.startswith('monthly_avg')]])

output_notebook()
show(plot_map(df=monthly_avg_4_july2023_pred, parameter_name='pustynia',
              colormap=dict(zip(['1', '0'], ['yellow', 'green'])),
              title='Pustynie (1) i niepustynie (0) - las losowy (lipiec 2023, średnia 4-letnia)',
              point_size=3, alpha=0.7))

"""##### Ocena na zbiorze treningowym"""

summary_model(rf_monthly_avg_4_july2023, X_train, y_train, ['0','1'])

show_metrics(rf_monthly_avg_4_july2023, X_train, y_train)

"""##### Ocena na zbiorze testowym"""

summary_model(rf_monthly_avg_4_july2023, X_test, y_test, ['0', '1'])

show_metrics(rf_monthly_avg_4_july2023, X_test, y_test)

"""### Średnie 5-letnie"""

X = monthly_avg_5_july2023_an_merge.drop(columns=['lon', 'lat', 'pustynia'])
y = monthly_avg_5_july2023_an_merge['pustynia']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2023)

rf_monthly_avg_5_july2023 = best_rf.copy()
rf_monthly_avg_5_july2023.fit(X_train, y_train)

"""Zastosujmy model na pełnych danych:"""

monthly_avg_5_july2023_pred = monthly_avg_5_july2023.copy()
monthly_avg_5_july2023_pred['pustynia'] = rf_monthly_avg_5_july2023.predict(monthly_avg_5_july2023.loc[:, [col for col in monthly_avg_5_july2023.columns if col.startswith('monthly_avg')]])

output_notebook()
show(plot_map(df=monthly_avg_5_july2023_pred, parameter_name='pustynia',
              colormap=dict(zip(['1', '0'], ['yellow', 'green'])),
              title='Pustynie (1) i niepustynie (0) - las losowy (lipiec 2023, średnia 5-letnia)',
              point_size=3, alpha=0.7))

"""##### Ocena na zbiorze treningowym"""

summary_model(rf_monthly_avg_5_july2023, X_train, y_train, ['0','1'])

show_metrics(rf_monthly_avg_5_july2023, X_train, y_train)

"""##### Ocena na zbiorze testowym"""

summary_model(rf_monthly_avg_5_july2023, X_test, y_test, ['0', '1'])

show_metrics(rf_monthly_avg_5_july2023, X_test, y_test)

"""## Wnioski

Wszystkie trzy modele na zbiorze testowym wypadają niemalże identycznie. Gdyby już musieć wybrać najlepszy model to byłby to model wytrenowany na 5-letnich średnich dla miesięcy, ale występujące w metrykach klasyfikacji różnice są zupełnie nieznaczne.

### Zapisanie najlepszego modelu
"""

import pickle
best_rf_path='/content/drive/MyDrive/BigMess/NASA/Modele/Klasyfikacja/Modele_kilkuletnia_agregacja/random_forest_5years_avg_july2023'
with open(best_rf_path, 'wb') as files:
  pickle.dump(rf_monthly_avg_5_july2023, files)

"""# LGBM

## Trening i test modelu przy użyciu nowych danych i zbioru anotowanego
"""

best_lgbm = lgb.LGBMClassifier(max_depth=10, n_estimators=120, num_leaves=30, random_state=3)

"""### Średnie 3-letnie"""

X = monthly_avg_3_july2023_an_merge.drop(columns=['lon', 'lat', 'pustynia'])
y = monthly_avg_3_july2023_an_merge['pustynia']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2023)

lgbm_monthly_avg_3_july2023 = best_lgbm.copy()
lgbm_monthly_avg_3_july2023.fit(X_train, y_train)

"""Zastosujmy model na pełnych danych:"""

monthly_avg_3_july2023_pred_lgbm = monthly_avg_3_july2023.copy()
monthly_avg_3_july2023_pred_lgbm['pustynia'] = lgbm_monthly_avg_3_july2023.predict(monthly_avg_3_july2023.loc[:, [col for col in monthly_avg_3_july2023.columns if col.startswith('monthly_avg')]])

output_notebook()
show(plot_map(df=monthly_avg_3_july2023_pred_lgbm, parameter_name='pustynia',
              colormap=dict(zip(['1', '0'], ['yellow', 'green'])),
              title='Pustynie (1) i niepustynie (0) - LGBM (lipiec 2023, średnia 3-letnia)',
              point_size=3, alpha=0.7))

"""##### Ocena na zbiorze treningowym"""

summary_model(lgbm_monthly_avg_3_july2023, X_train, y_train, ['0','1'])

show_metrics(lgbm_monthly_avg_3_july2023, X_train, y_train)

"""##### Ocena na zbiorze testowym"""

summary_model(lgbm_monthly_avg_3_july2023, X_test, y_test, ['0', '1'])

show_metrics(lgbm_monthly_avg_3_july2023, X_test, y_test)

"""##### Próba treningu na zbalansowanym datasecie"""

X_train_bal, y_train_bal = BalanceDataSet(X_train, y_train).useSMOTE()

lgbm_monthly_avg_3_july2023_bal = best_lgbm.copy()
lgbm_monthly_avg_3_july2023_bal.fit(X_train_bal, y_train_bal)

show_metrics(lgbm_monthly_avg_3_july2023_bal, X_train_bal, y_train_bal)

show_metrics(lgbm_monthly_avg_3_july2023_bal, X_test, y_test)

"""W tym wypadku model gorzej radzi sobie na zbiorze testowym.

### Średnie 4-letnie
"""

X = monthly_avg_4_july2023_an_merge.drop(columns=['lon', 'lat', 'pustynia'])
y = monthly_avg_4_july2023_an_merge['pustynia']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2023)

lgbm_monthly_avg_4_july2023 = best_lgbm.copy()
lgbm_monthly_avg_4_july2023.fit(X_train, y_train)

"""Zastosujmy model na pełnych danych:"""

monthly_avg_4_july2023_pred_lgbm = monthly_avg_4_july2023.copy()
monthly_avg_4_july2023_pred_lgbm['pustynia'] = lgbm_monthly_avg_4_july2023.predict(monthly_avg_4_july2023.loc[:, [col for col in monthly_avg_4_july2023.columns if col.startswith('monthly_avg')]])

output_notebook()
show(plot_map(df=monthly_avg_4_july2023_pred_lgbm, parameter_name='pustynia',
              colormap=dict(zip(['1', '0'], ['yellow', 'green'])),
              title='Pustynie (1) i niepustynie (0) - LGBM (lipiec 2023, średnia 4-letnia)',
              point_size=3, alpha=0.7))

"""##### Ocena na zbiorze treningowym"""

summary_model(lgbm_monthly_avg_4_july2023, X_train, y_train, ['0','1'])

show_metrics(lgbm_monthly_avg_4_july2023, X_train, y_train)

"""##### Ocena na zbiorze testowym"""

summary_model(lgbm_monthly_avg_4_july2023, X_test, y_test, ['0', '1'])

show_metrics(lgbm_monthly_avg_4_july2023, X_test, y_test)

"""### Średnie 5-letnie"""

X = monthly_avg_5_july2023_an_merge.drop(columns=['lon', 'lat', 'pustynia'])
y = monthly_avg_5_july2023_an_merge['pustynia']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2023)

lgbm_monthly_avg_5_july2023 = best_lgbm.copy()
lgbm_monthly_avg_5_july2023.fit(X_train, y_train)

"""Zastosujmy model na pełnych danych:"""

monthly_avg_5_july2023_pred_lgbm = monthly_avg_5_july2023.copy()
monthly_avg_5_july2023_pred_lgbm['pustynia'] = lgbm_monthly_avg_5_july2023.predict(monthly_avg_5_july2023.loc[:, [col for col in monthly_avg_5_july2023.columns if col.startswith('monthly_avg')]])

output_notebook()
show(plot_map(df=monthly_avg_5_july2023_pred_lgbm, parameter_name='pustynia',
              colormap=dict(zip(['1', '0'], ['yellow', 'green'])),
              title='Pustynie (1) i niepustynie (0) - LGBM (lipiec 2023, średnia 5-letnia)',
              point_size=3, alpha=0.7))

"""##### Ocena na zbiorze treningowym"""

summary_model(lgbm_monthly_avg_5_july2023, X_train, y_train, ['0','1'])

show_metrics(lgbm_monthly_avg_5_july2023, X_train, y_train)

"""##### Ocena na zbiorze testowym"""

summary_model(lgbm_monthly_avg_5_july2023, X_test, y_test, ['0', '1'])

show_metrics(lgbm_monthly_avg_5_july2023, X_test, y_test)

"""## Wnioski

Otrzymane modele są lepsze niż wytrenowane wcześniej lasy losowe. Zarówno dla danych treningowych, jak i testowych otrzymujemy lepsze wyniki. Ogólnie, wszystkie trzy modele na zbiorze testowym wypadają bardzo podobnie do siebie. Model wytrenowany na 5-letnich średnich dla miesięcy wydaje się być najmniej precyzyjny, w tym wypadku najlepszy wynik mamy dla 4-letnich średnich. Podsumowując wszystkie metryki klasyfikacji, najlepszym modelem jest model ze średnimi 4-letnimi.

### Zapisanie najlepszego modelu
"""

import pickle
best_lgbm_path='/content/drive/MyDrive/BigMess/NASA/Modele/Klasyfikacja/Modele_kilkuletnia_agregacja/lgbm_4years_avg_july2023'
with open(best_lgbm_path, 'wb') as files:
  pickle.dump(lgbm_monthly_avg_4_july2023, files)