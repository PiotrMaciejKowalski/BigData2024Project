# -*- coding: utf-8 -*-
"""agg_classification_eval.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oxlQ0p57z8f8PTVuej3ifeFouvITjHxQ
"""

# !pip install datashader
# !pip install holoviews hvplot colorcet
# !pip install geoviews
# !pip install pyspark

from typing import Tuple, List
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import sklearn
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import holoviews as hv
import geoviews as gv
import geoviews.tile_sources as gts
from holoviews.operation.datashader import datashade
import matplotlib as mpl
from pyspark.sql import DataFrame as SparkDataFrame, Window

def overYearMonthStats(df: SparkDataFrame, columns: List[str], n: int) -> SparkDataFrame:
    """
    Funkcja licząca średnie dla wybranych zmiennych dla danych współrzędnych geograficznych
    dla każdego z 12 miesięcy od roku w rozważanym pomiarze do n lat wstecz (tj. gdyby n=3, to
    średnia zostałaby wyliczona z rozważanego roku oraz 3 lat przed nim, czyli w praktyce mielibyśmy
    średnią z łącznie 4 lat).

    :param df: zbiór, na którym chcemy przeprowadzać operacje
    :param columns: lista nazw rozważanych kolumn ze zbioru danych
    :param n: liczba lat wstecz, z których chcemy wyliczyć średnią
    """

    assert columns

    windowSpec = Window.partitionBy("lon", "lat", "Month").orderBy("Year").rowsBetween(-n, 0)

    for column in columns:
        average_column_name = "monthly_avg_" + str(n) + "years_" + column
        df_window = df.withColumn(average_column_name, F.avg(F.col(column)).over(windowSpec))

    return df_window

def prepare_agg_data_for_training(nasa_sample_an: pd.DataFrame, year: int, month: int, n_years: int) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    Funkcja wyodrębniająca ze zagregowanych danych podzbiór zawierający dane z zadanego roku i miesiąca,
    ze średnimi z wybranej liczby lat. Pliki zagregowane znajdują się na dysku i mają ścieżki postaci
    '/content/drive/MyDrive/BigMess/NASA/monthly_avg/{n_years}years/NASA_monthly_avg_{year}.csv'.
    Zwracany jest wyodrębniony podzbiór oraz ramka danych powstała poprzez zmerge'owanie z danymi
    anotowanymi, w której pozostawione są kolumny 'lon', 'lat', 'pustynia' (zmienna objaśniana) oraz
    kolumny, których nazwy zaczynają się od "monthly_avg" (zmienne objaśniające).

    :param nasa_an_sample: zbiór zawierający dane anotowane
    :param year: rok, z którego dane mają być wyodrębnione
    :param month: miesiąc, z którego dane mają być wyodrębnione
    :param n_years: liczba lat wstecz z jakich dane mają być uśrednione
    """

    agg_path = f'/content/drive/MyDrive/BigMess/NASA/monthly_avg/{n_years}years/NASA_monthly_avg_{year}.csv'
    pd_monthly_avg = pd.read_csv(agg_path, index_col=0)
    monthly_avg = pd_monthly_avg[pd_monthly_avg['Month'] == month]
    monthly_avg_an_merged = pd_monthly_avg.merge(nasa_sample_an, left_on=['lon','lat'], right_on=['lon','lat'], how='inner')
    columns_to_leave = ['lon', 'lat', 'pustynia'] + [col for col in monthly_avg_an_merged.columns if col.startswith('monthly_avg')]
    return monthly_avg, monthly_avg_an_merged[columns_to_leave]

def plot_comparison(dfs: List[pd.DataFrame], var: str, n_locs: int = 10) -> None:
    """
    Funkcja generująca wykresy słupkowe, porównujące wartości wybranej zmiennej dla losowych
    lokalizacji z różnych zbiorów danych.

    :param dfs: lista zbiorów danych zawierających kolumny 'lon', 'lat' oraz zmienną w kolumnie
                o nazwie postaci 'monthly_avg_Xyears_Y'
    :param var: zmienna, której wartości będą porównywane
    :param n_locs: liczba losowych lokalizacji do porównania, domyślnie 10
    """

    # losowy wybór lokalizacji
    random_lon_lat = dfs[0][['lon', 'lat']].drop_duplicates().sample(n=n_locs, random_state=42)
    plt.figure(figsize=(12, 8))
    bar_width = 0.25

    # słownik wartości dla każdego zbioru danych
    values = {f'{i+3}-letnia': [
        df.query(f'lon == {lon} and lat == {lat}')[f'monthly_avg_{i+3}years_{var}'].iloc[0]
        for lon, lat in random_lon_lat[['lon', 'lat']].itertuples(index=False)]
        for i, df in enumerate(dfs)}

    # wykresy słupkowe dla każdego zbioru
    for i, period in enumerate([f'{i+3}-letnia' for i in range(len(dfs))]):
        x = np.arange(len(random_lon_lat)) + i * bar_width + (len(dfs) - 1) * bar_width / 2
        plt.bar(x, values[period], bar_width, label=period)

    plt.xlabel('Lokalizacja')
    plt.ylabel(f'Wartość {var}')
    plt.title(f'Porównanie wartości {var} dla losowych {n_locs} lokalizacji dla uśrednionych danych z kilku lat', fontsize=12)

    plt.xticks(np.arange(len(random_lon_lat)) + (len(dfs) - 1) * bar_width,
               [f'{lon}, {lat}' for lon, lat in zip(random_lon_lat['lon'], random_lon_lat['lat'])], fontsize=6.5, rotation=45)

    plt.legend(title='Średnia')
    plt.grid(True)
    plt.show()

def plot_map(df: pd.DataFrame, parameter_name: str, colormap: mpl.colors.LinearSegmentedColormap,
             title: str, point_size: int = 8, width: int = 900, height: int = 600, alpha: float = 1,
             bgcolor: str = 'white'):
    """
    Funkcja tworząca mapę dla zadanych współrzędnych geograficznych i określonego parametru.

    :param df: zbiór, którego część ma zostać przedstawiona na mapie; musi zawierać kolumny 'lon'
               i 'lat' oraz jakąś dodatkową zmienną
    :param parameter_name: nazwa kolumny, która ma zostać ujęta na mapie
    :param colormap: skala kolorystyczna dla punktów
    :param title: tytuł mapy
    :param point_size: rozmiar punktów przedstawianych na mapie, domyślnie równy 8
    :param width: szerokość okna zawierającego mapę, domyślnie równa 900
    :param height: wysokość okna zawierającego mapę, domyślnie równa 600
    :param alpha: przezroczystość punktów, domyślnie równa 1 (czyli brak przezroczystości)
    :param bgcolor: kolor tła okna zawierającego mapę, domyślnie biały
    """

    gdf = gv.Points(df, ['lon', 'lat'], [parameter_name]) # obiekt zawierający punkty
    tiles = gts.OSM # wybór mapy tła, w tym wypadku OpenStreetMap

    # łączenie mapy tła z punktami i ustawienie wybranych parametrów wizualizacji
    map_with_points = tiles * gdf.opts(
        title=title,
        color=parameter_name,
        cmap=colormap,
        size=point_size,
        width=width,
        height=height,
        colorbar=True,
        toolbar='above',
        tools=['hover', 'wheel_zoom', 'reset'],
        alpha=alpha,
        bgcolor=bgcolor
    )

    map_with_points.opts(bgcolor=bgcolor)

#    # zapis mapy do pliku .html
#    output_filename = f'/content/drive/MyDrive/BigMess/NASA/output_map_{parameter_name}.html'
#    hv.save(map_with_points, output_filename)

    return hv.render(map_with_points)

def show_metrics(model: sklearn.base.BaseEstimator, X: pd.DataFrame, y: pd.DataFrame) -> None:
    """
    Funkcja zwracająca cztery metryki oceniające klasyfikator.

    :param model: model klasyfikujący, który będzie oceniany
    :param X: zmienne objaśniające
    :param y: zmienna objaśniana, której predykcji chcemy dokonać
    """

    y_pred = model.predict(X)
#  print("Macierz błędu\n", confusion_matrix(y_true, y_pred), "\n")
    accuracy = accuracy_score(y, y_pred)
    print(f"Dokładność (accuracy): {accuracy*100:.2f}%")
    precision = precision_score(y, y_pred)
    print(f"Precyzja (precision): {precision*100:.2f}%")
    recall = recall_score(y, y_pred)
    print(f"Czułość (recall): {recall*100:.2f}%")
    f1 = f1_score(y, y_pred)
    print(f"F1-score: {f1*100:.2f}%")
